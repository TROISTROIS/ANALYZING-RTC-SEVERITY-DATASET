{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd654acd",
   "metadata": {},
   "source": [
    "# ANALYZING RTC SEVERITY DATASET\n",
    "In this project, we are analyzing rioad accident data in order to answer the following questions:\n",
    "1. When did most road accidents occur ? \n",
    "2. What hour ?\n",
    "3. Which day had the most/least accidents ?\n",
    "4. Which month has the most accidents ?\n",
    "5. Which roads lead to major road accidents.\n",
    "6. Are there specific locations that are prone to accidents ?\n",
    "7. Are there more accidents in rural/ urban areas ?\n",
    "8. Driving at which speed limit leads to accidents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d2c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import more_itertools\n",
    "import locale\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb7cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# get the encoding by reading the first ten lines\n",
    "with open(\"C://Users//user//Downloads//accident_data.csv//accident_data.csv\", mode='rb') as file:\n",
    "    raw_bytes = file.read(10)\n",
    "    detected_encoding = chardet.detect(raw_bytes)['encoding']\n",
    "    print(detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04100f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp1252\n"
     ]
    }
   ],
   "source": [
    "print(locale.getpreferredencoding())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d955ee",
   "metadata": {},
   "source": [
    "**CP1252** is the encoding used in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58124f6e",
   "metadata": {},
   "source": [
    "# **CONVERT THE FILE FROM *ASCII* ENCODING TO *UTF-8* ENCODING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62648d",
   "metadata": {},
   "source": [
    "## To convert a csv file file from one encoding to another:\n",
    "1. Convert the file from it's current encoding.\n",
    "2. Read the file using **csv.reader()**\n",
    "3. Open the new fike using the desired encoding\n",
    "4. Loop over the rows of the original file and write them into the new one using **csv.writer()** and the **writerow()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0583d6-bde4-43b0-80a2-916ef40aedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"C://Users//user//Downloads//accident_data.csv//accident_data.csv\") as file:\n",
    "    rows = list(csv.reader(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7f01f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Accident_Index', '1st_Road_Class', '1st_Road_Number', '2nd_Road_Class', '2nd_Road_Number', 'Accident_Severity', 'Carriageway_Hazards', 'Date', 'Day_of_Week', 'Did_Police_Officer_Attend_Scene_of_Accident', 'Junction_Control', 'Junction_Detail', 'Latitude', 'Light_Conditions', 'Local_Authority_(District)', 'Local_Authority_(Highway)', 'Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'LSOA_of_Accident_Location', 'Number_of_Casualties', 'Number_of_Vehicles', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Police_Force', 'Road_Surface_Conditions', 'Road_Type', 'Special_Conditions_at_Site', 'Speed_limit', 'Time', 'Urban_or_Rural_Area', 'Weather_Conditions', 'Year', 'InScotland'], ['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', '04/01/2005', 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '17:42', 'Urban', 'Raining no high winds', '2005', 'No'], ['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', '05/01/2005', 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', '17:36', 'Urban', 'Fine no high winds', '2005', 'No'], ['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '00:15', 'Urban', 'Fine no high winds', '2005', 'No'], ['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '10:35', 'Urban', 'Fine no high winds', '2005', 'No']]\n"
     ]
    }
   ],
   "source": [
    "print(rows[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26ef005-2934-44e7-922b-2a4752e20869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "header = rows[0]\n",
    "print(len(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923dc4c9-bddd-4a87-b066-6e6f001dc65c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "data = rows[1:]\n",
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ff55a",
   "metadata": {},
   "source": [
    "# EXPLORE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32905f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to explore the dataset to find out how many rows and columns there are\n",
    "def explore_dataset(dataset, start, end, rows_columns = False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_columns:\n",
    "        print(\"Number of rows\",len(dataset))\n",
    "        print(\"Number of columns\", len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "175d0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', '04/01/2005', 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '17:42', 'Urban', 'Raining no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', '05/01/2005', 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', '17:36', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '00:15', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '10:35', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00005', '', '0', '', '0', 'Slight', 'None', '10/01/2005', 'Monday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.495752', 'Darkness - lighting unknown', 'Kensington and Chelsea', 'Kensington and Chelsea', '528060', '179040', '-0.156618', 'E01002863', '1', '1', '0', '0', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '21:13', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "Number of rows 1048575\n",
      "Number of columns 34\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(data, 0,5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e05f5",
   "metadata": {},
   "source": [
    "# CHECK FOR WRONG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029c25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', '04/01/2005', 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '17:42', 'Urban', 'Raining no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', '05/01/2005', 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', '17:36', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '00:15', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '10:35', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00005', '', '0', '', '0', 'Slight', 'None', '10/01/2005', 'Monday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.495752', 'Darkness - lighting unknown', 'Kensington and Chelsea', 'Kensington and Chelsea', '528060', '179040', '-0.156618', 'E01002863', '1', '1', '0', '0', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '21:13', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "Number of rows 1048575\n",
      "Number of columns 34\n"
     ]
    }
   ],
   "source": [
    "# Remove empty lists\n",
    "data = [sublist for sublist in data if sublist]\n",
    "explore_dataset(data, 0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca6cef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84441d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', '', 'Motorway', 'A(M)']\n"
     ]
    }
   ],
   "source": [
    "roadtypes = []\n",
    "for row in data:\n",
    "    road_type = row[1]\n",
    "    if road_type not in roadtypes:\n",
    "        roadtypes.append(road_type)\n",
    "print(roadtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660054c1",
   "metadata": {},
   "source": [
    "# CHECK FOR DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de3ca7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate entries\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "duplicate_entries = []\n",
    "unique_entries = []\n",
    "for row in data:\n",
    "    accident_id = row[0]\n",
    "    if accident_id in unique_entries:\n",
    "        date_day_dicticate_entries.append(accident_id)\n",
    "#     else:\n",
    "#         unique_entries.append(accident_id)\n",
    "# len_unique_entries = len(unique_entries)\n",
    "len_duplicate_entries = len(duplicate_entries)\n",
    "# example_duplicate = duplicate_entries[3:5]\n",
    "# print(\"There are\", len_unique_entries, \"unique entries\")\n",
    "print(\"There are\", len_duplicate_entries, \"duplicate entries\")\n",
    "# print(example_duplicate)\n",
    "#     return len_duplicate_entries, len_unique_entries, example_duplicate\n",
    "# len_duplicate_entries, len_unique_entries, example_duplicate = check_duplicates(data)\n",
    "# print(\n",
    "#     f\"Number of duplicate entries {len_duplicate_entries}\\n\"\n",
    "#     f\"Number of unique entries  {len_unique_entries}\\n\"\n",
    "#     f\"Examples of duplicate entries {example_duplicate}\\n\"\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce57c1",
   "metadata": {},
   "source": [
    "# REPLACE MISSING STRINGS WITH \"UNKNOWN DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518c0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fill in the empty strings with the string(unknown Data)\n",
    "# def fill_missing_strings(i):\n",
    "#     for row in data:\n",
    "#         col = row[i]\n",
    "#         col = col.title()\n",
    "#         if not col:\n",
    "#             col = \"\"\n",
    "#         row[i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38cda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(header)):\n",
    "#     fill_missing_strings(i)\n",
    "# print(data[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424d31c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accident_Index': 0, '1st_Road_Class': 1, '1st_Road_Number': 2, '2nd_Road_Class': 3, '2nd_Road_Number': 4, 'Accident_Severity': 5, 'Carriageway_Hazards': 6, 'Date': 7, 'Day_of_Week': 8, 'Did_Police_Officer_Attend_Scene_of_Accident': 9, 'Junction_Control': 10, 'Junction_Detail': 11, 'Latitude': 12, 'Light_Conditions': 13, 'Local_Authority_(District)': 14, 'Local_Authority_(Highway)': 15, 'Location_Easting_OSGR': 16, 'Location_Northing_OSGR': 17, 'Longitude': 18, 'LSOA_of_Accident_Location': 19, 'Number_of_Casualties': 20, 'Number_of_Vehicles': 21, 'Pedestrian_Crossing-Human_Control': 22, 'Pedestrian_Crossing-Physical_Facilities': 23, 'Police_Force': 24, 'Road_Surface_Conditions': 25, 'Road_Type': 26, 'Special_Conditions_at_Site': 27, 'Speed_limit': 28, 'Time': 29, 'Urban_or_Rural_Area': 30, 'Weather_Conditions': 31, 'Year': 32, 'InScotland': 33}\n"
     ]
    }
   ],
   "source": [
    "# get the index of each column\n",
    "col_index = {}\n",
    "for i in range(len(header)):\n",
    "    col_index[header[i]] = i\n",
    "print(col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16031250-99c2-4ee1-ac19-f421a7b17d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for row in data:\n",
    "    myyear = row[32]\n",
    "    mydates = row[7]\n",
    "print(type(mydates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670dfed6",
   "metadata": {},
   "source": [
    "# PARSE STRINGS AS DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a013cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n",
      "<class 'datetime.time'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# parse strings as dates\n",
    "for row in data:\n",
    "    mydates = row[7]\n",
    "    if mydates:\n",
    "        mydates = dt.datetime.strptime(mydates, \"%d/%m/%Y\").date()\n",
    "        row[7] = mydates\n",
    "\n",
    "    mytime = row[29]\n",
    "#     replace Unknown Data Time with 00:00\n",
    "    if mytime:\n",
    "        mytime = dt.datetime.strptime(mytime, \"%H:%M\").time()\n",
    "        row[29] = mytime\n",
    "    \n",
    "    myyear = row[32]\n",
    "    if myyear:\n",
    "        myyear = dt.datetime.strptime(myyear, \"%Y\").year\n",
    "        row[32] = myyear\n",
    "    \n",
    "print(type(row[7]))\n",
    "print(type(row[29]))\n",
    "print(type(row[32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e87fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', datetime.date(2005, 1, 4), 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', datetime.time(17, 42), 'Urban', 'Raining no high winds', 2005, 'No']\n",
      "\n",
      "\n",
      "['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', datetime.date(2005, 1, 5), 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', datetime.time(17, 36), 'Urban', 'Fine no high winds', 2005, 'No']\n",
      "\n",
      "\n",
      "['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', datetime.date(2005, 1, 6), 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', datetime.time(0, 15), 'Urban', 'Fine no high winds', 2005, 'No']\n",
      "\n",
      "\n",
      "['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', datetime.date(2005, 1, 7), 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', datetime.time(10, 35), 'Urban', 'Fine no high winds', 2005, 'No']\n",
      "\n",
      "\n",
      "['200501BS00005', '', '0', '', '0', 'Slight', 'None', datetime.date(2005, 1, 10), 'Monday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.495752', 'Darkness - lighting unknown', 'Kensington and Chelsea', 'Kensington and Chelsea', '528060', '179040', '-0.156618', 'E01002863', '1', '1', '0', '0', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', datetime.time(21, 13), 'Urban', 'Fine no high winds', 2005, 'No']\n",
      "\n",
      "\n",
      "Number of rows 1048575\n",
      "Number of columns 34\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(data, 0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee98f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n",
      "1048575\n",
      "{datetime.date(2005, 1, 4): 'Tuesday', datetime.date(2005, 1, 5): 'Wednesday', datetime.date(2005, 1, 6): 'Thursday', datetime.date(2005, 1, 7): 'Friday'}\n",
      "[{'Date': datetime.date(2005, 1, 6), 'Day Of Week': 'Thursday'}, {'Date': datetime.date(2005, 1, 7), 'Day Of Week': 'Friday'}, {'Date': datetime.date(2005, 1, 10), 'Day Of Week': 'Monday'}]\n"
     ]
    }
   ],
   "source": [
    "dates_1 = []\n",
    "day_1 = []\n",
    "for row in data:    \n",
    "    mydate = row[7]\n",
    "    dates_1.append(mydate)\n",
    "    day_of_week = row[8]\n",
    "    day_1.append(day_of_week)\n",
    "print(len(dates_1))\n",
    "print(len(day_1))\n",
    "\n",
    "# Using the `zip` function to combine the two lists into a list of tuples\n",
    "date_data = list(zip(dates_1, day_1))\n",
    "\n",
    "# Converting the list of tuples to a dictionary\n",
    "date_dict = dict(date_data)\n",
    "# print the first few elements of the dictionary \n",
    "first_five = dict(list(date_dict.items())[:4])\n",
    "\n",
    "print(first_five)\n",
    "\n",
    "# Converting the dictionary to a list of dictionaries\n",
    "dict_list = [{'Date': key, 'Day Of Week': value} for key, value in date_dict.items()]\n",
    "print(dict_list[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "346dc80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['200501BS70083', 'B', '450', '', '0', 'Slight', 'None', datetime.date(2005, 3, 17), 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.517263', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '524290', '181340', '-0.210089', 'E01002831', '1', '1', '0', '4', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', datetime.time(9, 15), 'Urban', 'Fine no high winds', 2005, 'No'], ['200501BS70084', 'B', '450', 'Unclassified', '0', 'Slight', 'None', datetime.date(2005, 3, 13), 'Sunday', '3', 'Give way or uncontrolled', 'Crossroads', '51.516353', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524340', '181240', '-0.209404', 'E01002879', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', datetime.time(0, 15), 'Urban', 'Fine no high winds', 2005, 'No'], ['200501BS70085', 'C', '0', '', '0', 'Slight', 'None', datetime.date(2005, 3, 15), 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.524085', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '523920', '182090', '-0.215155', 'E01002905', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', datetime.time(13, 2), 'Urban', 'Fine no high winds', 2005, 'No'], ['200501BS70086', 'A', '308', 'C', '0', 'Slight', 'None', datetime.date(2005, 3, 14), 'Monday', '1', 'Auto traffic signal', 'Crossroads', '51.486931', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '526520', '178020', '-0.179156', 'E01002911', '1', '2', '0', '5', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', datetime.time(20, 0), 'Urban', 'Fine no high winds', 2005, 'No']]\n"
     ]
    }
   ],
   "source": [
    "print(data[100:104])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916f032",
   "metadata": {},
   "source": [
    "# THE MOST AND LEAST ACCIDENTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0dec654",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             casualties_by_hour[time] \u001b[38;5;241m=\u001b[39m casualties\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour\n\u001b[1;32m---> 41\u001b[0m accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour \u001b[38;5;241m=\u001b[39m \u001b[43mmost_least\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_first_few_data\u001b[39m(dictionary):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# first 5 key:value pairs\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     first_few \u001b[38;5;241m=\u001b[39m more_itertools\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m10\u001b[39m, dictionary\u001b[38;5;241m.\u001b[39mitems())\n",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36mmost_least\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     19\u001b[0m day \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     20\u001b[0m time \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mydates \u001b[38;5;129;01min\u001b[39;00m accidents_by_day:\n\u001b[0;32m     24\u001b[0m     accidents_by_day[mydates] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "def most_least(data):    \n",
    "    # which day had the most accidents?\n",
    "    result_list = []\n",
    "    for row in data:\n",
    "        accident_at = row[7]\n",
    "        no_casualties = int(row[20])\n",
    "        day_of_week = row[8]\n",
    "        my_time = row[29]\n",
    "        result_list.append([accident_at,no_casualties,day_of_week,my_time])\n",
    "\n",
    "    accidents_by_day = {}\n",
    "    casualties_by_day = {}\n",
    "    day_accident = {}\n",
    "    accidents_by_hour = {}\n",
    "    casualties_by_hour = {}\n",
    "    for result in result_list:\n",
    "        mydates = result[0]\n",
    "        casualties = result[1]\n",
    "        day = result[2]\n",
    "        time = result[3]\n",
    "        time = time.strftime(\"%H\")\n",
    " \n",
    "        if mydates in accidents_by_day:\n",
    "            accidents_by_day[mydates] += 1\n",
    "            casualties_by_day[mydates] += casualties\n",
    "        else:\n",
    "            accidents_by_day[mydates] = 1\n",
    "            casualties_by_day[mydates] = casualties\n",
    "        if day in day_accident:\n",
    "            day_accident[day] += 1\n",
    "        else:\n",
    "            day_accident[day] = 1\n",
    "        if time in accidents_by_hour:\n",
    "            accidents_by_hour[time] += 1\n",
    "            casualties_by_hour[time] = casualties\n",
    "        else:\n",
    "            accidents_by_hour[time] = 1\n",
    "            casualties_by_hour[time] = casualties\n",
    "            \n",
    "    return accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour\n",
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour = most_least(data)\n",
    "\n",
    "def print_first_few_data(dictionary):\n",
    "    # first 5 key:value pairs\n",
    "    first_few = more_itertools.take(10, dictionary.items())\n",
    "    return first_few\n",
    "\n",
    "def sorted_values(dictionary):\n",
    "    # sort the dictionary to get it in descending order\n",
    "    #sort to see the when most accidents occured and the least\n",
    "    sorted_dict = dict(sorted(dictionary.items(), reverse = True, key=lambda item: item[1]))\n",
    "    sorted_dict1 = print_first_few_data(sorted_dict)\n",
    "    return sorted_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ee29023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten accidents by date are: \n",
      "  [(datetime.date(2005, 1, 4), 473), (datetime.date(2005, 1, 5), 523), (datetime.date(2005, 1, 6), 553), (datetime.date(2005, 1, 7), 510), (datetime.date(2005, 1, 10), 523), (datetime.date(2005, 1, 11), 549), (datetime.date(2005, 1, 13), 657), (datetime.date(2005, 1, 14), 715), (datetime.date(2005, 1, 15), 461), (datetime.date(2005, 1, 16), 412)]\n",
      "The first ten casualties by date are: \n",
      "  [(datetime.date(2005, 1, 4), 599), (datetime.date(2005, 1, 5), 686), (datetime.date(2005, 1, 6), 710), (datetime.date(2005, 1, 7), 656), (datetime.date(2005, 1, 10), 688), (datetime.date(2005, 1, 11), 734), (datetime.date(2005, 1, 13), 900), (datetime.date(2005, 1, 14), 949), (datetime.date(2005, 1, 15), 662), (datetime.date(2005, 1, 16), 610)]\n",
      "The first ten accidents by hour are: \n",
      "  [('15', 1048575)]\n",
      "The first ten casualties by hour are: \n",
      "  [('15', 1)]\n",
      "The first ten accidents by day in ascending order:\n",
      " [(datetime.date(2005, 10, 21), 822), (datetime.date(2005, 11, 18), 787), (datetime.date(2006, 9, 29), 784), (datetime.date(2006, 9, 22), 780), (datetime.date(2005, 12, 7), 775), (datetime.date(2006, 12, 1), 750), (datetime.date(2005, 9, 30), 749), (datetime.date(2005, 12, 9), 748), (datetime.date(2005, 10, 12), 746), (datetime.date(2005, 12, 19), 744)]\n",
      "The first ten casualties by day in ascending order:\n",
      " [(datetime.date(2005, 10, 21), 1157), (datetime.date(2006, 9, 22), 1139), (datetime.date(2006, 9, 29), 1075), (datetime.date(2005, 12, 9), 1060), (datetime.date(2005, 11, 18), 1019), (datetime.date(2006, 10, 6), 1014), (datetime.date(2005, 9, 15), 1012), (datetime.date(2005, 9, 30), 1002), (datetime.date(2005, 11, 4), 1001), (datetime.date(2005, 12, 7), 999)]\n",
      "The first ten accidents by hour in ascending order:\n",
      " [('15', 1048575)]\n",
      "The first ten casualties by hour in ascending order:\n",
      " [('15', 1)]\n",
      "The number of accidents per day are: \n",
      "  [('Tuesday', 156119), ('Wednesday', 157992), ('Thursday', 155788), ('Friday', 171910), ('Monday', 148506), ('Saturday', 142227), ('Sunday', 116033)]\n",
      "The sorted number of accidents per day are: \n",
      "  [('Friday', 171910), ('Wednesday', 157992), ('Tuesday', 156119), ('Thursday', 155788), ('Monday', 148506), ('Saturday', 142227), ('Sunday', 116033)]\n"
     ]
    }
   ],
   "source": [
    "print(\"The first ten accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(dictionary):\n",
    "    maxx = None\n",
    "    minn = None\n",
    "    for key in dictionary:\n",
    "        if maxx is None or dictionary[key] > maxx:\n",
    "            maxx = dictionary[key]\n",
    "        if minn is None or dictionary[key] < minn:\n",
    "            minn = dictionary[key]\n",
    "    highest_period = None\n",
    "    lowest_period = None\n",
    "    for key in dictionary:\n",
    "        if dictionary[key] == maxx:\n",
    "            highest_period = key\n",
    "        if dictionary[key] == minn:\n",
    "            lowest_period = key\n",
    "    return maxx, minn, highest_period,lowest_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71581dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(casualties_by_day)\n",
    "print(\"The most number of casualties is {} and occured in {}\".format(maxx,highest_period))\n",
    "print(\"The least number of casualties is {} and occured in {}\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(accidents_by_day)\n",
    "print(\"The most number of accidents is {} and occured in {}\".format(maxx,highest_period))\n",
    "print(\"The least number of accidents is {} and occured in {}\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(day_accident)\n",
    "print(\"The most number of accidents is {} and occured on {}\".format(maxx,highest_period))\n",
    "print(\"The least number of accidents is {} and occured on {}\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33783ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(casualties_by_hour)\n",
    "print(\"The most number of casualties is {} and occured at the {}th hour\".format(maxx,highest_period))\n",
    "print(\"The least number of casualties is {} and occured at the {}th hour\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(accidents_by_hour)\n",
    "print(\"The most number of accidents is {} and occured at the {}th hour\".format(maxx,highest_period))\n",
    "print(\"The least number of accidents is {} and occured at the {}th hour\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd8cd6",
   "metadata": {},
   "source": [
    "# FINDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49285b",
   "metadata": {},
   "source": [
    "1. The most number of casualties is **1157** and occured on **2005-10-21**\n",
    "2. The least number of casualties is **157** and occured in **2010-01-10**\n",
    "3. The most number of accidents is **822** and occured on **2005-10-21**\n",
    "4. The least number of accidents is **118** and occured on **2008-12-25**\n",
    "5. Most accidents were **171910** which occured on **Friday**\n",
    "6. The least accidents were **116033** which occured on **Sunday**\n",
    "7. The most number of casualties by hour is **8** and occured at the **16th** hour\n",
    "8. The least number of casualties is **1** and occured at the **06** hour\n",
    "9. The most number of accidents by hour is **91861** and occured at the **17th** hour\n",
    "10. The least number of accidents by hour is **5789** and occured at the **04th** hour\n",
    "11. A lot of accidents occur in urban areas, rural areas have got half as much.\n",
    "12. **Bingham, Nottingham, UK(52.949719, -0.977611)** has the most accidents.\n",
    "13. Even though **30km/hr** seems ideal to be driving at, most accidents still result from the same\n",
    "14. There are **138,192** serious accidents, **895,883** slight accidents, **14,500** fatal accidents and **0** unclassified accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27724f36",
   "metadata": {},
   "source": [
    "# DO MOST ACCIDENTS HAPPEN IN RURAL OR URBAN AREAS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_count(data,index):\n",
    "    count_dict = {}\n",
    "    for row in data:\n",
    "        column = row[index]\n",
    "        if column not in count_dict:\n",
    "            count_dict[column] = 1\n",
    "        else:\n",
    "            count_dict[column] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef014767",
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_or_urban = my_count(data,30)\n",
    "print(sorted_values(rural_or_urban))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_limit = my_count(data,28)\n",
    "print(sorted_values(speed_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ece2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accidents_location(data):\n",
    "    coordinates = {}\n",
    "    for row in data:\n",
    "        accident_at = row[7]\n",
    "        latitude = row[12]\n",
    "        longitude = row[18]\n",
    "        coords = (latitude,longitude)\n",
    "        if coords in coordinates:\n",
    "            coordinates[coords] += 1\n",
    "        else:\n",
    "            coordinates[coords] = 1\n",
    "    return coordinates\n",
    "coordinates = accidents_location(data)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6355f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which of these combinations have the most accidents?\n",
    "sorted_values(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed8c6b",
   "metadata": {},
   "source": [
    "# THE SPEED LIMIT UNDER WHICH MOST ACCIDENTS OCCURED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine roadclass and road number then compare\n",
    "full_road1 = []\n",
    "full_road2 = []\n",
    "for row in data:\n",
    "    road_class = row[1]\n",
    "    road_number = row[2]\n",
    "    road_class2 = row[3]\n",
    "    road_number2 = row[4]\n",
    "    if road_class and road_number:\n",
    "        full_road1.append(road_class+road_number)\n",
    "    else:\n",
    "        full_road.append(None)\n",
    "    if road_class2 and road_number2:\n",
    "        full_road2.append(road_class2+road_number2)\n",
    "    else:\n",
    "        full_road2.append(None)\n",
    "print(full_road1[:20])\n",
    "print(full_road2[:10])\n",
    "#we can't do much with the roads as there is a lot of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcffe89",
   "metadata": {},
   "source": [
    "# OUT OF WHAT WE HAVE, WHICH ONES ARE THE SEVERE, FATAL AND SERIOUS ACCIDENTS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists for the three categories of accidents\n",
    "Serious = []\n",
    "Slight = []\n",
    "Fatal = []\n",
    "Unclassified = []\n",
    "# iterate through the rows and append to each list accordingly\n",
    "for row in data:\n",
    "    severity = row[5]\n",
    "    if severity.startswith(\"Serious\"):\n",
    "        Serious.append(row)\n",
    "    elif severity.startswith(\"Slight\"):\n",
    "        Slight.append(row)\n",
    "    elif severity.startswith(\"Fatal\"):\n",
    "        Fatal.append(row)\n",
    "    else:\n",
    "        Unclassified.append(row)\n",
    "print(\"There are {0:,} serious accidents\".format(len(Serious)))      \n",
    "print(\"There are {0:,} slight accidents\".format(len(Slight)))\n",
    "print(\"There are {0:,} fatal accidents\".format(len(Fatal)))\n",
    "print(\"There are {} unclassified accidents\".format(len(Unclassified)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fcc94",
   "metadata": {},
   "source": [
    "# ANALYSIS OF FATAL ACCIDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6846714",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour=most_least(Fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77848e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten fatal accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties from fatal accidents by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten fatal accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties from fata l accidents by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten fatal accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties from fatal accidents by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten fatal accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties from fatal accidents by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of fatal accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of fatal accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour=most_least(Serious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten serious accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties from serious accidents by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten serious accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties from serious accidents by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten serious accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties from serious accidents by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten serious accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties from serious accidents by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of serious accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of serious accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour=most_least(Slight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten slight accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties from slight accidents by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten slight accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties from slight accidents by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten slight accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties from slight accidents by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten slight accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties from slight accidents by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of slight accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of slight accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd570c-2434-4848-8579-c036bc0bd3de",
   "metadata": {},
   "source": [
    "# CHECK FOR THE CORRECT DATATYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78957c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checktypes(data,header):    \n",
    "    # Initialize a dictionary to store the data types for each column\n",
    "    column_data_types = {col: None for col in header}\n",
    "\n",
    "    # Iterate over each row of the CSV file\n",
    "    for row in data:\n",
    "        # Iterate over each column in the row\n",
    "        for i, col_value in enumerate(row):\n",
    "            # Check if the data type for the column has been set yet\n",
    "            if not column_data_types[header[i]]:\n",
    "                # If not, set the data type to the type of the current value\n",
    "                column_data_types[header[i]] = type(col_value)\n",
    "            else:\n",
    "                # If it has been set, check if the current value has a different data type\n",
    "                if column_data_types[header[i]] != type(col_value):\n",
    "                    # If it does, set the data type to a generic \"object\" type\n",
    "                    column_data_types[header[i]] = object\n",
    "\n",
    "    # Print the data types for each column\n",
    "    for col, data_type in column_data_types.items():\n",
    "        print(f\"{col}: {data_type.__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "checktypes(data,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to check for the count of values\n",
    "def unique_count(data,index):\n",
    "    unique_dict = {}\n",
    "    for row in data:\n",
    "        column = row[index]\n",
    "        if column not in unique_dict:\n",
    "            unique_dict[column] = 1\n",
    "        else:\n",
    "            unique_dict[column] += 1\n",
    "    return unique_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = unique_count(data,20)\n",
    "print(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_sum(dict):\n",
    "    total = 0\n",
    "    for key in dict:\n",
    "        total += dict[key]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_sum(mydict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6650e",
   "metadata": {},
   "source": [
    "# FINDINGS\n",
    "Columns that have str type yet are integers:\n",
    "1. 1st_Road_Number\n",
    "2. 2nd_Road_Number\n",
    "3. Did_Police_Officer_Attend_Scene_of_Accident\n",
    "4. Latitude\n",
    "5. Longitude\n",
    "6. Location_Easting_OSGR\n",
    "7. Location_Northing_OSGR\n",
    "8. Number of Vehicles\n",
    "9. Number of casualties\n",
    "10. Pedestrian_Crossing-Human_Control\n",
    "11. Pedestrian_Crossing-Physical_Facilities\n",
    "12. Speed_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35e32c",
   "metadata": {},
   "source": [
    "# CONVERT STRING DATA TYPES TO INT/FLOAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5552d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns with wrong data type\n",
    "non_strings_int = ['1st_Road_Number', '2nd_Road_Number','Did_Police_Officer_Attend_Scene_of_Accident',\n",
    "            'Location_Easting_OSGR','Location_Northing_OSGR','Number_of_Vehicles','Number_of_Casualties',\n",
    "            'Pedestrian_Crossing-Human_Control','Speed_limit','Pedestrian_Crossing-Physical_Facilities']\n",
    "non_strings_float = ['Latitude','Longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(non_strings_int))\n",
    "print(len(non_strings_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column indices of the column with the wrong data\n",
    "def get_index(header, mylist):\n",
    "    cols_convert = []\n",
    "    for j in range(len(header)):\n",
    "        for i in range(len(mylist)):\n",
    "            if mylist[i] == header[j]:\n",
    "                cols_convert.append(j)\n",
    "    return cols_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_columns_to_convert = get_index(header,non_strings_int)\n",
    "float_columns_to_convert = get_index(header,non_strings_float)\n",
    "print(int_columns_to_convert)\n",
    "print(float_columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467af74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert(data,header,alist):\n",
    "#     converted_data = []\n",
    "#     # Iterate through each row in the CSV file\n",
    "#     for row in data:\n",
    "#         # Convert the specified columns to int\n",
    "#         for i in alist:\n",
    "            \n",
    "#             if row[i] != \"Unknown Data\" and row[i] != \"Na\":\n",
    "#                 row[col_idx] = int(row[col_idx])\n",
    "#         # Add the converted row to the list of converted data\n",
    "#         converted_data.append(row)\n",
    "\n",
    "#     # Write the converted data to a new CSV file\n",
    "#     with open('converted_example.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "#         # Create a CSV writer object\n",
    "#         writer = csv.writer(csvfile)\n",
    "\n",
    "#         # Write the header row\n",
    "#         writer.writerow(header)\n",
    "\n",
    "#         # Write the converted data\n",
    "#         writer.writerows(converted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert(data,header,int_columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0157804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert(data,header,mylist):\n",
    "#     converted_data = []\n",
    "#     # Iterate through each row in the CSV file\n",
    "#     for row in data:\n",
    "#         # Convert the specified columns to int\n",
    "#         for col_idx in mylist:\n",
    "#             if row[col_idx] != \"Unknown Data\" and row[col_idx] != \"Na\":\n",
    "#                 row[col_idx] = float(row[col_idx])\n",
    "#         # Add the converted row to the list of converted data\n",
    "#         converted_data.append(row)\n",
    "\n",
    "#     # Write the converted data to a new CSV file\n",
    "#     with open('converted_example.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "#         # Create a CSV writer object\n",
    "#         writer = csv.writer(csvfile)\n",
    "\n",
    "#         # Write the header row\n",
    "#         writer.writerow(header)\n",
    "\n",
    "#         # Write the converted data\n",
    "#         writer.writerows(converted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa039986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert(data,header,float_columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32106c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the new csv file \n",
    "# with open(\"converted_example.csv\") as file:\n",
    "#     new_data = list(csv.reader(file))\n",
    "#     header = new_data[0]\n",
    "#     new_rows = new_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore_dataset(new_data, 0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checktypes(new_data,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec7317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
