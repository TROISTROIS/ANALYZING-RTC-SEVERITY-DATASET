{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd654acd",
   "metadata": {},
   "source": [
    "# ANALYZING RTC SEVERITY DATASET\n",
    "In this project, we are analyzing rioad accident data in order to answer the following questions:\n",
    "1. When did most road accidents occur ? \n",
    "2. What hour ?\n",
    "3. Which day had the most/least accidents ?\n",
    "4. Which month has the most accidents ?\n",
    "5. Which roads lead to major road accidents.\n",
    "6. Are there specific locations that are prone to accidents ?\n",
    "7. Are there more accidents in rural/ urban areas ?\n",
    "8. Driving at which speed limit leads to accidents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d2c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import more_itertools\n",
    "import locale\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb7cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# get the encoding by reading the first ten lines\n",
    "with open(\"C://Users//user//Downloads//accident_data.csv//accident_data.csv\", mode='rb') as file:\n",
    "    raw_bytes = file.read(10)\n",
    "    detected_encoding = chardet.detect(raw_bytes)['encoding']\n",
    "    print(detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04100f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp1252\n"
     ]
    }
   ],
   "source": [
    "print(locale.getpreferredencoding())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d955ee",
   "metadata": {},
   "source": [
    "**CP1252** is the encoding used in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58124f6e",
   "metadata": {},
   "source": [
    "# **CONVERT THE FILE FROM *ASCII* ENCODING TO *UTF-8* ENCODING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62648d",
   "metadata": {},
   "source": [
    "## To convert a csv file file from one encoding to another:\n",
    "1. Convert the file from it's current encoding.\n",
    "2. Read the file using **csv.reader()**\n",
    "3. Open the new fike using the desired encoding\n",
    "4. Loop over the rows of the original file and write them into the new one using **csv.writer()** and the **writerow()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0583d6-bde4-43b0-80a2-916ef40aedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"C://Users//user//Downloads//accident_data.csv//accident_data.csv\") as file:\n",
    "    rows = list(csv.reader(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7f01f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Accident_Index', '1st_Road_Class', '1st_Road_Number', '2nd_Road_Class', '2nd_Road_Number', 'Accident_Severity', 'Carriageway_Hazards', 'Date', 'Day_of_Week', 'Did_Police_Officer_Attend_Scene_of_Accident', 'Junction_Control', 'Junction_Detail', 'Latitude', 'Light_Conditions', 'Local_Authority_(District)', 'Local_Authority_(Highway)', 'Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'LSOA_of_Accident_Location', 'Number_of_Casualties', 'Number_of_Vehicles', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Police_Force', 'Road_Surface_Conditions', 'Road_Type', 'Special_Conditions_at_Site', 'Speed_limit', 'Time', 'Urban_or_Rural_Area', 'Weather_Conditions', 'Year', 'InScotland'], ['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', '04/01/2005', 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '17:42', 'Urban', 'Raining no high winds', '2005', 'No'], ['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', '05/01/2005', 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', '17:36', 'Urban', 'Fine no high winds', '2005', 'No'], ['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '00:15', 'Urban', 'Fine no high winds', '2005', 'No'], ['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '10:35', 'Urban', 'Fine no high winds', '2005', 'No']]\n"
     ]
    }
   ],
   "source": [
    "print(rows[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26ef005-2934-44e7-922b-2a4752e20869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "header = rows[0]\n",
    "print(len(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923dc4c9-bddd-4a87-b066-6e6f001dc65c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "data = rows[1:]\n",
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ff55a",
   "metadata": {},
   "source": [
    "# EXPLORE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32905f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to explore the dataset to find out how many rows and columns there are\n",
    "def explore_dataset(dataset, start, end, rows_columns = False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_columns:\n",
    "        print(\"Number of rows\",len(dataset))\n",
    "        print(\"Number of columns\", len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "175d0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', '04/01/2005', 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '17:42', 'Urban', 'Raining no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', '05/01/2005', 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', '17:36', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '00:15', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '10:35', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00005', '', '0', '', '0', 'Slight', 'None', '10/01/2005', 'Monday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.495752', 'Darkness - lighting unknown', 'Kensington and Chelsea', 'Kensington and Chelsea', '528060', '179040', '-0.156618', 'E01002863', '1', '1', '0', '0', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '21:13', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "Number of rows 1048575\n",
      "Number of columns 34\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(data, 0,5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e05f5",
   "metadata": {},
   "source": [
    "# CHECK FOR WRONG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029c25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200501BS00001', 'A', '3218', '', '0', 'Serious', 'None', '04/01/2005', 'Tuesday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.489096', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '525680', '178240', '-0.19117', 'E01002849', '1', '1', '0', '1', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '17:42', 'Urban', 'Raining no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00002', 'B', '450', 'C', '0', 'Slight', 'None', '05/01/2005', 'Wednesday', '1', 'Auto traffic signal', 'Crossroads', '51.520075', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524170', '181650', '-0.211708', 'E01002909', '1', '1', '0', '5', 'Metropolitan Police', 'Dry', 'Dual carriageway', 'None', '30', '17:36', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00003', 'C', '0', '', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.525301', 'Darkness - lights lit', 'Kensington and Chelsea', 'Kensington and Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '00:15', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00004', 'A', '3220', '', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.482442', '', 'Kensington and Chelsea', 'Kensington and Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single carriageway', 'None', '30', '10:35', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "['200501BS00005', '', '0', '', '0', 'Slight', 'None', '10/01/2005', 'Monday', '1', 'Data missing or out of range', 'Not at junction or within 20 metres', '51.495752', 'Darkness - lighting unknown', 'Kensington and Chelsea', 'Kensington and Chelsea', '528060', '179040', '-0.156618', 'E01002863', '1', '1', '0', '0', 'Metropolitan Police', 'Wet or damp', 'Single carriageway', 'None', '30', '21:13', 'Urban', 'Fine no high winds', '2005', 'No']\n",
      "\n",
      "\n",
      "Number of rows 1048575\n",
      "Number of columns 34\n"
     ]
    }
   ],
   "source": [
    "# Remove empty lists\n",
    "data = [sublist for sublist in data if sublist]\n",
    "explore_dataset(data, 0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca6cef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84441d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', '', 'Motorway', 'A(M)']\n"
     ]
    }
   ],
   "source": [
    "roadtypes = []\n",
    "for row in data:\n",
    "    road_type = row[1]\n",
    "    if road_type not in roadtypes:\n",
    "        roadtypes.append(road_type)\n",
    "print(roadtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660054c1",
   "metadata": {},
   "source": [
    "# CHECK FOR DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de3ca7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate entries\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "duplicate_entries = []\n",
    "unique_entries = []\n",
    "for row in data:\n",
    "    accident_id = row[0]\n",
    "    if accident_id in unique_entries:\n",
    "        date_day_dicticate_entries.append(accident_id)\n",
    "#     else:\n",
    "#         unique_entries.append(accident_id)\n",
    "# len_unique_entries = len(unique_entries)\n",
    "len_duplicate_entries = len(duplicate_entries)\n",
    "# example_duplicate = duplicate_entries[3:5]\n",
    "# print(\"There are\", len_unique_entries, \"unique entries\")\n",
    "print(\"There are\", len_duplicate_entries, \"duplicate entries\")\n",
    "# print(example_duplicate)\n",
    "#     return len_duplicate_entries, len_unique_entries, example_duplicate\n",
    "# len_duplicate_entries, len_unique_entries, example_duplicate = check_duplicates(data)\n",
    "# print(\n",
    "#     f\"Number of duplicate entries {len_duplicate_entries}\\n\"\n",
    "#     f\"Number of unique entries  {len_unique_entries}\\n\"\n",
    "#     f\"Examples of duplicate entries {example_duplicate}\\n\"\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce57c1",
   "metadata": {},
   "source": [
    "# REPLACE MISSING STRINGS WITH \"NAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518c0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the empty strings with the string(unknown Data)\n",
    "def fill_missing_strings(i):\n",
    "    for row in data:\n",
    "        col = row[i]\n",
    "        col = col.title()\n",
    "        if not col:\n",
    "            col = \"NaN\"\n",
    "        row[i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38cda63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['200501Bs00003', 'C', '0', 'NaN', '0', 'Slight', 'None', '06/01/2005', 'Thursday', '1', 'Data Missing Or Out Of Range', 'Not At Junction Or Within 20 Metres', '51.525301', 'Darkness - Lights Lit', 'Kensington And Chelsea', 'Kensington And Chelsea', '524520', '182240', '-0.206458', 'E01002857', '1', '2', '0', '0', 'Metropolitan Police', 'Dry', 'Single Carriageway', 'None', '30', '00:15', 'Urban', 'Fine No High Winds', '2005', 'No'], ['200501Bs00004', 'A', '3220', 'NaN', '0', 'Slight', 'None', '07/01/2005', 'Friday', '1', 'Data Missing Or Out Of Range', 'Not At Junction Or Within 20 Metres', '51.482442', 'NaN', 'Kensington And Chelsea', 'Kensington And Chelsea', '526900', '177530', '-0.173862', 'E01002840', '1', '1', '0', '0', 'Metropolitan Police', 'Dry', 'Single Carriageway', 'None', '30', '10:35', 'Urban', 'Fine No High Winds', '2005', 'No'], ['200501Bs00005', 'NaN', '0', 'NaN', '0', 'Slight', 'None', '10/01/2005', 'Monday', '1', 'Data Missing Or Out Of Range', 'Not At Junction Or Within 20 Metres', '51.495752', 'Darkness - Lighting Unknown', 'Kensington And Chelsea', 'Kensington And Chelsea', '528060', '179040', '-0.156618', 'E01002863', '1', '1', '0', '0', 'Metropolitan Police', 'Wet Or Damp', 'Single Carriageway', 'None', '30', '21:13', 'Urban', 'Fine No High Winds', '2005', 'No']]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(header)):\n",
    "    fill_missing_strings(i)\n",
    "print(data[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424d31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accident_Index': 0, '1st_Road_Class': 1, '1st_Road_Number': 2, '2nd_Road_Class': 3, '2nd_Road_Number': 4, 'Accident_Severity': 5, 'Carriageway_Hazards': 6, 'Date': 7, 'Day_of_Week': 8, 'Did_Police_Officer_Attend_Scene_of_Accident': 9, 'Junction_Control': 10, 'Junction_Detail': 11, 'Latitude': 12, 'Light_Conditions': 13, 'Local_Authority_(District)': 14, 'Local_Authority_(Highway)': 15, 'Location_Easting_OSGR': 16, 'Location_Northing_OSGR': 17, 'Longitude': 18, 'LSOA_of_Accident_Location': 19, 'Number_of_Casualties': 20, 'Number_of_Vehicles': 21, 'Pedestrian_Crossing-Human_Control': 22, 'Pedestrian_Crossing-Physical_Facilities': 23, 'Police_Force': 24, 'Road_Surface_Conditions': 25, 'Road_Type': 26, 'Special_Conditions_at_Site': 27, 'Speed_limit': 28, 'Time': 29, 'Urban_or_Rural_Area': 30, 'Weather_Conditions': 31, 'Year': 32, 'InScotland': 33}\n"
     ]
    }
   ],
   "source": [
    "# get the index of date column\n",
    "col_index = {}\n",
    "for i in range(len(header)):\n",
    "    col_index[header[i]] = i\n",
    "print(col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16031250-99c2-4ee1-ac19-f421a7b17d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for row in data:\n",
    "    myyear = row[32]\n",
    "    mydates = row[7]\n",
    "print(type(mydates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670dfed6",
   "metadata": {},
   "source": [
    "# PARSE STRINGS AS DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a013cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data 'NaN' does not match format '%H:%M'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     replace Unknown Data Time with 00:00\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     mytime\u001b[38;5;241m=\u001b[39mmytime\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown Data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     mytime \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m     row[\u001b[38;5;241m29\u001b[39m] \u001b[38;5;241m=\u001b[39m mytime\n\u001b[0;32m     13\u001b[0m     myyear \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m32\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data 'NaN' does not match format '%H:%M'"
     ]
    }
   ],
   "source": [
    "# parse strings as dates\n",
    "for row in data:\n",
    "    mydates = row[7]\n",
    "    mydates = dt.datetime.strptime(mydates, \"%d/%m/%Y\").date()\n",
    "    row[7] = mydates\n",
    "\n",
    "    mytime = row[29]\n",
    "#     replace Unknown Data Time with 00:00\n",
    "    mytime=mytime.replace(\"Unknown Data\",\"00:00\")\n",
    "    mytime = dt.datetime.strptime(mytime, \"%H:%M\").time()\n",
    "    row[29] = mytime\n",
    "    \n",
    "    myyear = row[32]\n",
    "    myyear = dt.datetime.strptime(myyear, \"%Y\").year\n",
    "    row[32] = myyear\n",
    "    \n",
    "print(type(row[7]))\n",
    "print(type(row[29]))\n",
    "print(type(row[32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee98f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_1 = []\n",
    "day_1 = []\n",
    "for row in data:    \n",
    "    mydate = row[7]\n",
    "    dates_1.append(mydate)\n",
    "    day_of_week = row[8]\n",
    "    day_1.append(day_of_week)\n",
    "print(len(dates_1))\n",
    "print(len(day_1))\n",
    "\n",
    "# Using the `zip` function to combine the two lists into a list of tuples\n",
    "date_data = list(zip(dates_1, day_1))\n",
    "\n",
    "# Converting the list of tuples to a dictionary\n",
    "date_dict = dict(date_data)\n",
    "# print the first few elements of the dictionary \n",
    "first_five = dict(list(date_dict.items())[:4])\n",
    "\n",
    "print(first_five)\n",
    "\n",
    "# Converting the dictionary to a list of dictionaries\n",
    "dict_list = [{'Date': key, 'Day Of Week': value} for key, value in date_dict.items()]\n",
    "print(dict_list[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346dc80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data[100:104])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916f032",
   "metadata": {},
   "source": [
    "# THE MOST AND LEAST ACCIDENTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dec654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_least(data):    \n",
    "    # which day had the most accidents?\n",
    "    result_list = []\n",
    "    for row in data:\n",
    "        accident_at = row[7]\n",
    "        no_casualties = int(row[20])\n",
    "        day_of_week = row[8]\n",
    "        my_time = row[29]\n",
    "        result_list.append([accident_at,no_casualties,day_of_week,my_time])\n",
    "\n",
    "    accidents_by_day = {}\n",
    "    casualties_by_day = {}\n",
    "    day_accident = {}\n",
    "    accidents_by_hour = {}\n",
    "    casualties_by_hour = {}\n",
    "    for result in result_list:\n",
    "        mydates = result[0]\n",
    "        casualties = result[1]\n",
    "        day = result[2]\n",
    "        time = result[3]\n",
    "        time = time.strftime(\"%H\")\n",
    " \n",
    "        if mydates in accidents_by_day:\n",
    "            accidents_by_day[mydates] += 1\n",
    "            casualties_by_day[mydates] += casualties\n",
    "        else:\n",
    "            accidents_by_day[mydates] = 1\n",
    "            casualties_by_day[mydates] = casualties\n",
    "        if day in day_accident:\n",
    "            day_accident[day] += 1\n",
    "        else:\n",
    "            day_accident[day] = 1\n",
    "        if time in accidents_by_hour:\n",
    "            accidents_by_hour[time] += 1\n",
    "            casualties_by_hour[time] = casualties\n",
    "        else:\n",
    "            accidents_by_hour[time] = 1\n",
    "            casualties_by_hour[time] = casualties\n",
    "            \n",
    "    return accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour\n",
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour = most_least(data)\n",
    "\n",
    "def print_first_few_data(dictionary):\n",
    "    # first 5 key:value pairs\n",
    "    first_few = more_itertools.take(10, dictionary.items())\n",
    "    return first_few\n",
    "\n",
    "def sorted_values(dictionary):\n",
    "    # sort the dictionary to get it in descending order\n",
    "    #sort to see the when most accidents occured and the least\n",
    "    sorted_dict = dict(sorted(dictionary.items(), reverse = True, key=lambda item: item[1]))\n",
    "    sorted_dict1 = print_first_few_data(sorted_dict)\n",
    "    return sorted_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee29023",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(dictionary):\n",
    "    maxx = None\n",
    "    minn = None\n",
    "    for key in dictionary:\n",
    "        if maxx is None or dictionary[key] > maxx:\n",
    "            maxx = dictionary[key]\n",
    "        if minn is None or dictionary[key] < minn:\n",
    "            minn = dictionary[key]\n",
    "    highest_period = None\n",
    "    lowest_period = None\n",
    "    for key in dictionary:\n",
    "        if dictionary[key] == maxx:\n",
    "            highest_period = key\n",
    "        if dictionary[key] == minn:\n",
    "            lowest_period = key\n",
    "    return maxx, minn, highest_period,lowest_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71581dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(casualties_by_day)\n",
    "print(\"The most number of casualties is {} and occured in {}\".format(maxx,highest_period))\n",
    "print(\"The least number of casualties is {} and occured in {}\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(accidents_by_day)\n",
    "print(\"The most number of accidents is {} and occured in {}\".format(maxx,highest_period))\n",
    "print(\"The least number of accidents is {} and occured in {}\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(day_accident)\n",
    "print(\"The most number of accidents is {} and occured on {}\".format(maxx,highest_period))\n",
    "print(\"The least number of accidents is {} and occured on {}\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33783ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(casualties_by_hour)\n",
    "print(\"The most number of casualties is {} and occured at the {}th hour\".format(maxx,highest_period))\n",
    "print(\"The least number of casualties is {} and occured at the {}th hour\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, minn, highest_period,lowest_period = minmax(accidents_by_hour)\n",
    "print(\"The most number of accidents is {} and occured at the {}th hour\".format(maxx,highest_period))\n",
    "print(\"The least number of accidents is {} and occured at the {}th hour\".format(minn,lowest_period))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd8cd6",
   "metadata": {},
   "source": [
    "# FINDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49285b",
   "metadata": {},
   "source": [
    "1. The most number of casualties is **1157** and occured on **2005-10-21**\n",
    "2. The least number of casualties is **157** and occured in **2010-01-10**\n",
    "3. The most number of accidents is **822** and occured on **2005-10-21**\n",
    "4. The least number of accidents is **118** and occured on **2008-12-25**\n",
    "5. Most accidents were **171910** which occured on **Friday**\n",
    "6. The least accidents were **116033** which occured on **Sunday**\n",
    "7. The most number of casualties by hour is **8** and occured at the **16th** hour\n",
    "8. The least number of casualties is **1** and occured at the **06** hour\n",
    "9. The most number of accidents by hour is **91861** and occured at the **17th** hour\n",
    "10. The least number of accidents by hour is **5789** and occured at the **04th** hour\n",
    "11. A lot of accidents occur in urban areas, rural areas have got half as much.\n",
    "12. **Bingham, Nottingham, UK(52.949719, -0.977611)** has the most accidents.\n",
    "13. Even though **30km/hr** seems ideal to be driving at, most accidents still result from the same\n",
    "14. There are **138,192** serious accidents, **895,883** slight accidents, **14,500** fatal accidents and **0** unclassified accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27724f36",
   "metadata": {},
   "source": [
    "# DO MOST ACCIDENTS HAPPEN IN RURAL OR URBAN AREAS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_count(data,index):\n",
    "    count_dict = {}\n",
    "    for row in data:\n",
    "        column = row[index]\n",
    "        if column not in count_dict:\n",
    "            count_dict[column] = 1\n",
    "        else:\n",
    "            count_dict[column] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef014767",
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_or_urban = my_count(data,30)\n",
    "print(sorted_values(rural_or_urban))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_limit = my_count(data,28)\n",
    "print(sorted_values(speed_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ece2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accidents_location(data):\n",
    "    coordinates = {}\n",
    "    for row in data:\n",
    "        accident_at = row[7]\n",
    "        latitude = row[12]\n",
    "        longitude = row[18]\n",
    "        coords = (latitude,longitude)\n",
    "        if coords in coordinates:\n",
    "            coordinates[coords] += 1\n",
    "        else:\n",
    "            coordinates[coords] = 1\n",
    "    return coordinates\n",
    "coordinates = accidents_location(data)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6355f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which of these combinations have the most accidents?\n",
    "sorted_values(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed8c6b",
   "metadata": {},
   "source": [
    "# THE SPEED LIMIT UNDER WHICH MOST ACCIDENTS OCCURED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine roadclass and road number then compare\n",
    "full_road1 = []\n",
    "full_road2 = []\n",
    "for row in data:\n",
    "    road_class = row[1]\n",
    "    road_number = row[2]\n",
    "    road_class2 = row[3]\n",
    "    road_number2 = row[4]\n",
    "    if road_class and road_number:\n",
    "        full_road1.append(road_class+road_number)\n",
    "    else:\n",
    "        full_road.append(None)\n",
    "    if road_class2 and road_number2:\n",
    "        full_road2.append(road_class2+road_number2)\n",
    "    else:\n",
    "        full_road2.append(None)\n",
    "print(full_road1[:20])\n",
    "print(full_road2[:10])\n",
    "#we can't do much with the roads as there is a lot of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcffe89",
   "metadata": {},
   "source": [
    "# OUT OF WHAT WE HAVE, WHICH ONES ARE THE SEVERE, FATAL AND SERIOUS ACCIDENTS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists for the three categories of accidents\n",
    "Serious = []\n",
    "Slight = []\n",
    "Fatal = []\n",
    "Unclassified = []\n",
    "# iterate through the rows and append to each list accordingly\n",
    "for row in data:\n",
    "    severity = row[5]\n",
    "    if severity.startswith(\"Serious\"):\n",
    "        Serious.append(row)\n",
    "    elif severity.startswith(\"Slight\"):\n",
    "        Slight.append(row)\n",
    "    elif severity.startswith(\"Fatal\"):\n",
    "        Fatal.append(row)\n",
    "    else:\n",
    "        Unclassified.append(row)\n",
    "print(\"There are {0:,} serious accidents\".format(len(Serious)))      \n",
    "print(\"There are {0:,} slight accidents\".format(len(Slight)))\n",
    "print(\"There are {0:,} fatal accidents\".format(len(Fatal)))\n",
    "print(\"There are {} unclassified accidents\".format(len(Unclassified)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fcc94",
   "metadata": {},
   "source": [
    "# ANALYSIS OF FATAL ACCIDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6846714",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour=most_least(Fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77848e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten fatal accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties from fatal accidents by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten fatal accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties from fata l accidents by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten fatal accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties from fatal accidents by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten fatal accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties from fatal accidents by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of fatal accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of fatal accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour=most_least(Serious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten serious accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties from serious accidents by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten serious accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties from serious accidents by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten serious accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties from serious accidents by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten serious accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties from serious accidents by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of serious accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of serious accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_by_day, casualties_by_day, day_accident, accidents_by_hour, casualties_by_hour=most_least(Slight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first ten slight accidents by date are: \\n \", print_first_few_data(accidents_by_day))\n",
    "print(\"The first ten casualties from slight accidents by date are: \\n \", print_first_few_data(casualties_by_day))\n",
    "print(\"The first ten slight accidents by hour are: \\n \", print_first_few_data(accidents_by_hour))\n",
    "print(\"The first ten casualties from slight accidents by hour are: \\n \", print_first_few_data(casualties_by_hour))\n",
    "print(\"The first ten slight accidents by day in ascending order:\\n\", sorted_values(accidents_by_day ))\n",
    "print(\"The first ten casualties from slight accidents by day in ascending order:\\n\", sorted_values(casualties_by_day))\n",
    "print(\"The first ten slight accidents by hour in ascending order:\\n\", sorted_values(accidents_by_hour ))\n",
    "print(\"The first ten casualties from slight accidents by hour in ascending order:\\n\", sorted_values(casualties_by_hour))\n",
    "print(\"The number of slight accidents per day are: \\n \", print_first_few_data(day_accident))\n",
    "print(\"The sorted number of slight accidents per day are: \\n \", sorted_values(day_accident))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd570c-2434-4848-8579-c036bc0bd3de",
   "metadata": {},
   "source": [
    "# CHECK FOR THE CORRECT DATATYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b791395-993b-440e-9f53-adaa97525c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in data:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100f939-8e27-4a53-8cd9-248d4dac6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatypes = {}\n",
    "column_types = [type(col) for col in data[0]]\n",
    "# Iterate over each row to determine the data type of each column\n",
    "for row in data:\n",
    "    for i, col_value in enumerate(row):\n",
    "        column_type = type(col_value)\n",
    "\n",
    "        # Check if the data type of the current column is different from the previous rows\n",
    "        if column_type != column_types[i]:\n",
    "            column_types[i] = object \n",
    "# Print the data types of each column\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac9ec4-4c31-4111-9f33-3370e2c511c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use zip() to combine the two lists into a single list of tuples, then use a dictionary comprehension to create the dictionary\n",
    "my_dict = {h: c for h, c in zip(header, column_types)}\n",
    "# Print the resulting dictionary\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66e573-69ea-4c66-8309-4f1ff2d83286",
   "metadata": {},
   "source": [
    "# FINDINGS\n",
    "Columns that have str type yet are integers:\n",
    "1. 1st_Road_Number\n",
    "2. 2nd_Road_Number\n",
    "3. Latitude\n",
    "4. Longitude\n",
    "5. Location_Easting_OSGR\n",
    "6. Location_Northing_OSGR\n",
    "7. Number of Vehicles\n",
    "8. Number of casualties\n",
    "9. Pedestrian_Crossing-Human_Control\n",
    "10. Pedestrian_Crossing-Physical_Facilities\n",
    "11. Speed_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8041282-373f-4a0b-91f2-20d086f4841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns to integers\n",
    "non_strings = ['1st_Road_Number', '2nd_Road_Number','Latitude','Longitude','Location_Easting_OSGR','Location_Northing_OSGR' \n",
    "               ,'Number of Vehicles','Number of casualties','Pedestrian_Crossing-Human_Control','Speed_limit',\n",
    "               'Pedestrian_Crossing-Physical_Facilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef114190-472b-4349-9604-1c0cea42510d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
